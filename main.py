# main.py
import os
import asyncio
from io import BytesIO
from tempfile import NamedTemporaryFile

import aiohttp
from PIL import Image, UnidentifiedImageError
from dotenv import load_dotenv

from aiogram import Bot, Dispatcher, Router, F
from aiogram.types import Message
from aiogram.filters import Command

# ----------------- –ó–∞–≥—Ä—É–∑–∫–∞ .env -----------------
dotenv_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".env")
load_dotenv(dotenv_path)

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY –≤ .env")

# ----------------- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram -----------------
bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()
router = Router()
dp.include_router(router)

# ----------------- –ö–æ–Ω—Ñ–∏–≥ OpenAI endpoint -----------------
OPENAI_IMAGES_EDIT_URL = "https://api.openai.com/v1/images/edits"
OPENAI_HEADERS = {"Authorization": f"Bearer {OPENAI_API_KEY}"}

# ----------------- –°–ª–æ–≤–∞—Ä—å –æ–∂–∏–¥–∞—é—â–∏—Ö —Ñ–æ—Ç–æ -----------------
pending_photos: dict[int, dict] = {}

# ----------------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ -----------------
def prepare_image_bytes_for_openai(in_bytes: bytes, want_size: int = 1024) -> tuple[bytes, str]:
    """
    –û—Ç–∫—Ä—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Pillow, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ RGB (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ),
    –æ–±—Ä–µ–∑–∞–µ—Ç –ø–æ —Ü–µ–Ω—Ç—Ä—É –≤ –∫–≤–∞–¥—Ä–∞—Ç –∏ —Ä–µ—Å–∞–π–∑–∏—Ç –¥–æ want_size x want_size.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (bytes, mime_type) ‚Äî bytes –≤ —Ñ–æ—Ä–º–∞—Ç–µ PNG.
    """
    try:
        img = Image.open(BytesIO(in_bytes))
    except UnidentifiedImageError:
        raise ValueError("–§–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω Pillow.")

    # Convert to RGBA/RGB depending on presence of alpha
    if img.mode not in ("RGB", "RGBA"):
        img = img.convert("RGBA" if "A" in img.mode else "RGB")

    # Crop to square (center) then resize
    w, h = img.size
    side = min(w, h)
    left = (w - side) // 2
    upper = (h - side) // 2
    right = left + side
    lower = upper + side
    img = img.crop((left, upper, right, lower))
    img = img.resize((want_size, want_size), Image.LANCZOS)

    # Save as PNG (PNG is safe; JPEG would lose alpha)
    out = BytesIO()
    img.save(out, format="PNG")
    out_bytes = out.getvalue()
    return out_bytes, "image/png"

async def openai_images_edit_send(image_bytes: bytes, prompt: str, session: aiohttp.ClientSession):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç multipart POST –∫ /v1/images/edits —Å image –∏ prompt.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict JSON –æ—Ç–≤–µ—Ç–∞.
    """
    form = aiohttp.FormData()
    form.add_field("model", "gpt-image-1")
    form.add_field("prompt", prompt)
    form.add_field("size", "1024x1024")
    # –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º —Ñ–∞–π–ª ‚Äî –¥–∞—ë–º –∏–º—è –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π content_type
    form.add_field("image", image_bytes, filename="input.png", content_type="image/png")

    # –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ - —è–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
    timeout = aiohttp.ClientTimeout(total=180)
    async with session.post(OPENAI_IMAGES_EDIT_URL, headers=OPENAI_HEADERS, data=form, timeout=timeout) as resp:
        text = await resp.text()
        try:
            js = await resp.json()
        except Exception:
            raise RuntimeError(f"OpenAI returned non-JSON response (status {resp.status}): {text}")
        if resp.status >= 400:
            # –ø–æ–ø—Ä–æ–±—É–µ–º –≤–µ—Ä–Ω—É—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—É—é –æ—à–∏–±–∫—É –∏–∑ OpenAI, –µ—Å–ª–∏ –µ—Å—Ç—å
            msg = js.get("error", {}).get("message") if isinstance(js, dict) else text
            raise RuntimeError(f"OpenAI API error (status {resp.status}): {msg}")
        return js

# ----------------- –•—ç–Ω–¥–ª–µ—Ä—ã -----------------
@router.message(Command(commands=["start", "help"]))
async def cmd_start(message: Message):
    await message.reply(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî —Ñ–æ—Ç–æ-—Ä–µ–¥–∞–∫—Ç–æ—Ä.\n"
        "1) –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ (JPG/PNG/WEBP/–∏ —Ç.–ø.)\n"
        "2) –ó–∞—Ç–µ–º –ø—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç ‚Äî —á—Ç–æ —Å –Ω–∏–º —Å–¥–µ–ª–∞—Ç—å.\n\n"
        "–Ø –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–≤–æ—à/–º–∞—Å—à—Ç–∞–±) –∏ –ø—Ä–∏—à–ª—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
    )

@router.message(F.photo)
async def on_photo(message: Message):
    pending_photos[message.from_user.id] = {"file_id": message.photo[-1].file_id}
    await message.reply("üì∏ –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ. –¢–µ–ø–µ—Ä—å –ø—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç ‚Äî —á—Ç–æ —Å –Ω–∏–º —Å–¥–µ–ª–∞—Ç—å.")

@router.message()
async def on_text(message: Message):
    user_id = message.from_user.id
    if user_id not in pending_photos:
        await message.reply("–°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é üòä")
        return

    prompt = message.text.strip()
    file_id = pending_photos[user_id]["file_id"]
    pending_photos.pop(user_id, None)

    await message.reply("ü™Ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥...")

    tmp_path = None
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –∏–∑ Telegram
        file_obj = await bot.get_file(file_id)
        file_path = file_obj.file_path
        file_url = f"https://api.telegram.org/file/bot{TELEGRAM_TOKEN}/{file_path}"

        # –°–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        async with aiohttp.ClientSession() as session:
            async with session.get(file_url) as resp:
                if resp.status != 200:
                    raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: HTTP {resp.status}")
                orig_bytes = await resp.read()
                # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º bytes (crop/resize/convert) –¥–ª—è OpenAI
                processed_bytes, mime = prepare_image_bytes_for_openai(orig_bytes, want_size=1024)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenAI
            result_json = await openai_images_edit_send(processed_bytes, prompt, session)

        # –†–∞–∑–±–æ—Ä –æ—Ç–≤–µ—Ç–∞: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º 'url' –∏ 'b64_json'
        image_data = None
        if isinstance(result_json, dict) and "data" in result_json and len(result_json["data"]) > 0:
            d0 = result_json["data"][0]
            if "url" in d0 and d0["url"]:
                image_url = d0["url"]
                # –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Å—ã–ª–∞–µ–º URL –∫–∞–∫ —Ñ–æ—Ç–æ
                await bot.send_photo(chat_id=message.chat.id, photo=image_url, caption="‚úÖ –ì–æ—Ç–æ–≤–æ!")
                return
            elif "b64_json" in d0 and d0["b64_json"]:
                import base64
                raw = base64.b64decode(d0["b64_json"])
                image_data = raw

        if image_data:
            await bot.send_photo(chat_id=message.chat.id, photo=BytesIO(image_data), caption="‚úÖ –ì–æ—Ç–æ–≤–æ!")
            return

        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ OpenAI.")

    except Exception as e:
        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç OpenAI –≥–æ–≤–æ—Ä–∏—Ç –æ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ, –≤—ã–¥–∞—ë–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        msg = str(e)
        if "Country, region, or territory not supported" in msg or "not supported" in msg:
            msg += "\n\n–ü–æ—Ö–æ–∂–µ, –≤–∞—à –∞–∫–∫–∞—É–Ω—Ç/—Ä–µ–≥–∏–æ–Ω –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è OpenAI Images API ‚Äî —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ —É—á—ë—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å VPN/–¥—Ä—É–≥—É—é —É—á—ë—Ç–Ω—É—é –∑–∞–ø–∏—Å—å OpenAI –∏–ª–∏ Azure OpenAI (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ), –∏–ª–∏ —Å–≤—è–∂–∏—Ç–µ—Å—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π OpenAI."
        await message.reply(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {msg}")

# ----------------- –ó–∞–ø—É—Å–∫ -----------------
async def main():
    print("ü§ñ Bot is running...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
